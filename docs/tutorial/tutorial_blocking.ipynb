{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking API\n",
    "\n",
    "Blocking is a technique that makes record linkage scalable. It is achieved by partitioning datasets into groups, called blocks and only comparing records in corresponding blocks. This can reduce the number of comparisons that need to be conducted to find which pairs of records should be linked.\n",
    "\n",
    "Different blocking techniques have different methods to partition datasets in order to reduce as much number of comparisons as possible while maintain high pair completeness.\n",
    "\n",
    "In this tutorial, we demonstrate how to use blocking in privacy preserving record linkage. \n",
    "\n",
    "Load example Nothern Caroline vote dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recid</th>\n",
       "      <th>givenname</th>\n",
       "      <th>surname</th>\n",
       "      <th>suburb</th>\n",
       "      <th>pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>761859</td>\n",
       "      <td>kate</td>\n",
       "      <td>chapman</td>\n",
       "      <td>brighton</td>\n",
       "      <td>4017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1384455</td>\n",
       "      <td>lian</td>\n",
       "      <td>hurse</td>\n",
       "      <td>carisbrook</td>\n",
       "      <td>3464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1933333</td>\n",
       "      <td>matthew</td>\n",
       "      <td>russo</td>\n",
       "      <td>bardon</td>\n",
       "      <td>4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1564695</td>\n",
       "      <td>lorraine</td>\n",
       "      <td>zammit</td>\n",
       "      <td>minchinbury</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5971993</td>\n",
       "      <td>ingo</td>\n",
       "      <td>richardson</td>\n",
       "      <td>woolsthorpe</td>\n",
       "      <td>3276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     recid givenname     surname       suburb    pc\n",
       "0   761859      kate     chapman     brighton  4017\n",
       "1  1384455      lian       hurse   carisbrook  3464\n",
       "2  1933333   matthew       russo       bardon  4065\n",
       "3  1564695  lorraine      zammit  minchinbury  2770\n",
       "4  5971993      ingo  richardson  woolsthorpe  3276"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_alice = pd.read_csv('data/alice.csv')\n",
    "df_alice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, `recid` contains record identifier which can be used to assess the quality of blocking. \n",
    "\n",
    "Next step is to config a blocking job. Before we do that, let's look at the blocking methods we are currently supporting:\n",
    "\n",
    "1. Probabilistic signature (p-sig)\n",
    "2. LSH based $\\Lambda$-fold redundant (lambda-fold)\n",
    "\n",
    "Let's firstly look at P-sig\n",
    "\n",
    "### Blocking Methods - Probabilistic signature (p-sig)\n",
    "\n",
    "This blocking method uses signatures as the blocking key and place only records having same signatures into the same block. \n",
    "\n",
    "Let's see an example of configuration for `p-sig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocking_config = {\n",
    "    \"type\": \"p-sig\",\n",
    "    \"version\": 1,\n",
    "    \"config\": {\n",
    "        \"blocking_features\": [1],\n",
    "#         \"record-id-col\": 0,\n",
    "        \"filter\": {\n",
    "            \"type\": \"ratio\",\n",
    "            \"max\": 0.02,\n",
    "            \"min\": 0.00,\n",
    "        },\n",
    "        \"blocking-filter\": {\n",
    "            \"type\": \"bloom filter\",\n",
    "            \"number-hash-functions\": 4,\n",
    "            \"bf-len\": 2048,\n",
    "        },\n",
    "        \"signatureSpecs\": [\n",
    "            [\n",
    "                 {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 1},\n",
    "                 {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 2},\n",
    "            ],\n",
    "            [\n",
    "                {\"type\": \"metaphone\", \"feature-idx\": 1},\n",
    "                {\"type\": \"metaphone\", \"feature-idx\": 2},\n",
    "            ]\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1 - Generate Signature**\n",
    "\n",
    "For a record `r`, a signature is a sub-record deriving from record `r` with a signature strategy. For example, a signature strategy could be taking the initial of names and concatenating letters together i.e. if we have a record with name `\"John White\"` the signature for this record is `\"JW\"`.\n",
    "\n",
    "We provide the following signature strategies:\n",
    "\n",
    "* feature-value: the signature is generated by returning the selected feature\n",
    "* characters-at: the signature is generated by selecting a single character or a sequence of characters from selected feature\n",
    "* metaphone: the signature is generated by phonetic encoding the selected feature using metaphone\n",
    "\n",
    "The output of this step is a reversed index where keys are generated signatures / blocking key and the values are list of record IDs. The record IDs could be row index or the actual record identifier if it is available in the dataset.\n",
    "\n",
    "The configuration of signature strategies is in `signatureSpecs` section. For example, in the above configuration, we are going to generate two signatures for each record. The first signature is a combination of 3 signature strategies\n",
    "\n",
    "```\n",
    "     {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 1},\n",
    "     {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 2},\n",
    "     {\"type\": \"feature-value\", \"feature_idx\": 4}\n",
    "\n",
    "```\n",
    "It is a combination of name initials and postcode.\n",
    "\n",
    "The second signature is generated by a combination of 2 signatuer strategies:\n",
    "```\n",
    "    {\"type\": \"metaphone\", \"feature-idx\": 1},\n",
    "    {\"type\": \"metaphone\", \"feature-idx\": 2},\n",
    "```\n",
    "That is phonetic encoding of first name and last name.\n",
    "\n",
    "**Step2 - Filter Too Frequent Signatures**\n",
    "\n",
    "A signature is assumed to identify a record as uniquely as possible. Therefore, we need to filter out some too frequent signatures since they can uniquely identify the record. On the otherside, we want to be resilient to frequency attack, so we need to filter out too rare signature that only contains very few records. The configuration of filtering is in the `filter` part. For example, in the above configuration, the filter section is configured as:\n",
    "```\n",
    "    \"filter\": {\n",
    "        \"type\": \"ratio\",\n",
    "        \"max\": 0.02,\n",
    "        \"min\": 0.001,\n",
    "    }\n",
    "```\n",
    "Then we will filter out all signatures / blocks whose number of records is greater than 2% of number of total records or is less than 0.1% of number of total records. \n",
    "\n",
    "Note that we also support absoulte filtering configuration i.e. filter by number of counts. For example:\n",
    "\n",
    "```\n",
    "    \"filter\": {\n",
    "        \"type\": \"count\",\n",
    "        \"max\": 100,\n",
    "        \"min\": 5,\n",
    "    }\n",
    "```\n",
    "\n",
    "**Step3 - Anonymization**\n",
    "\n",
    "Given we want to do privacy preserving record linkage, the signatures need to be hashed to avoid leaking of PII information. The most frequent used data structure of such encoding is Bloom Filter. Here we use one Bloom Filter and map all filtered signatures into that Bloom Filter. The configuration of Bloom Filter is in `block-filter` section:\n",
    "\n",
    "```\n",
    "    \"blocking-filter\": {\n",
    "        \"type\": \"bloom filter\",\n",
    "        \"number-hash-functions\": 20,\n",
    "        \"bf-len\": 2048,\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "After anonymization, the signature becomes the set of indices of bits 1 in the bloom filter and hence can preseve the privacy of data for each data provider.\n",
    "\n",
    "### Carry out Blocking Job\n",
    "\n",
    "Okay, once you have a good understanding of the P-Sig blocking, we can carry out our blocking job with `blocklib`. Firstly, we need to process the data a bit since `blocklib` only accept list of tuples as input data.\n",
    "\n",
    "**Step1 - Generate Candidate Blocks for Party A - Alice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example PII [761859, 'kate', 'chapman', 'brighton', 4017]\n"
     ]
    }
   ],
   "source": [
    "data_alice = df_alice.to_dict(orient='split')['data']\n",
    "print(\"Example PII\", data_alice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Blocks:   5011\n",
      "Minimum Block Size: 1\n",
      "Maximum Block Size: 61\n",
      "Average Block Size: 1\n",
      "Median Block Size:  1\n",
      "Standard Deviation of Block Size:  3.8424497488253815\n"
     ]
    }
   ],
   "source": [
    "from blocklib import generate_candidate_blocks\n",
    "\n",
    "block_obj_alice = generate_candidate_blocks(data_alice, blocking_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics of blocks are printed for you to inspect the block distribution and decide if this is a good blocking result. Here both average and median block sizes are 1 which is resilient to frequency attack. \n",
    "\n",
    "You can get the blocking instance and blocks/reversed indice in the `block_obj_alice`. Let's get the first signature in the reversed indcies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<blocklib.pprlpsig.PPRLIndexPSignature object at 0x10511ea90>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(416, 1650, 836, 1230)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(block_obj_alice.state)\n",
    "list(block_obj_alice.blocks.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the example signature for Alice is a set of indices of bits 1 in Bloom Filter. Next we want to do the same thing for another party - Bob.\n",
    "\n",
    "**Step2 - Generate Candidate Blocks for Party B - Bob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Blocks:   5004\n",
      "Minimum Block Size: 1\n",
      "Maximum Block Size: 59\n",
      "Average Block Size: 1\n",
      "Median Block Size:  1\n",
      "Standard Deviation of Block Size:  3.841316259098635\n",
      "<blocklib.pprlpsig.PPRLIndexPSignature object at 0x1131f9750>\n",
      "(96, 1146, 148, 1198)\n",
      "[0, 446]\n"
     ]
    }
   ],
   "source": [
    "df_bob = pd.read_csv('data/bob.csv')\n",
    "data_bob = df_bob.to_dict(orient='split')['data']\n",
    "block_obj_bob = generate_candidate_blocks(data_bob, blocking_config)\n",
    "print(block_obj_bob.state)\n",
    "print(list(block_obj_bob.blocks.keys())[0])\n",
    "print(list(block_obj_bob.blocks.values())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Final Blocks\n",
    "\n",
    "Now we have candidate blocks from both parties, we can generate final blocks by only including signatures that appear in both parties. Instead of directly comparing signature, the algorithm will firstly map the list of signatures into a bloom filter for both parites, and then take the and operation on two bloom filter to decide the common ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice: 5011 out of 5011 blocks are in common\n",
      "Bob:   5001 out of 5001 blocks are in common\n"
     ]
    }
   ],
   "source": [
    "from blocklib import generate_blocks_2party\n",
    "\n",
    "filtered_blocks_alice, filtered_blocks_bob = generate_blocks_2party([block_obj_alice, block_obj_bob])\n",
    "print('Alice: {} out of {} blocks are in common'.format(len(filtered_blocks_alice), len(block_obj_alice.blocks)))\n",
    "print('Bob:   {} out of {} blocks are in common'.format(len(filtered_blocks_bob), len(block_obj_bob.blocks)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Blocking\n",
    "\n",
    "We can assess the blocking result when we have ground truth . There are two main metrics to assess blocking result:\n",
    "\n",
    "* reduction ratio: the percentage of reduced number of comparisons\n",
    "* pair completeness: the percentage of true matches after blocking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rr = 0.9961\n",
      "pc = 1.0\n"
     ]
    }
   ],
   "source": [
    "from blocklib.assess import assess_blocks_2party\n",
    "\n",
    "\n",
    "subdata1 = [[x[0]] for x in data_alice]\n",
    "subdata2 = [[x[0]] for x in data_bob]\n",
    "\n",
    "rr, pc = assess_blocks_2party([filtered_blocks_alice, filtered_blocks_bob],\n",
    "                              [subdata1, subdata2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
