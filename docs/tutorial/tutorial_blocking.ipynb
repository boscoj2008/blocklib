{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking API\n",
    "\n",
    "Blocking is a technique that makes record linkage scalable. It is achieved by partitioning datasets into groups, called blocks and only comparing records in corresponding blocks. This can reduce the number of comparisons that need to be conducted to find which pairs of records should be linked.\n",
    "\n",
    "Different blocking techniques have different methods to partition datasets in order to reduce as much number of comparisons as possible while maintain high pair completeness.\n",
    "\n",
    "In this tutorial, we demonstrate how to use blocking in privacy preserving record linkage. \n",
    "\n",
    "Load example Nothern Caroline vote dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_alice = pd.read_csv('data/alice.csv')\n",
    "df_alice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, `recid` contains record identifier which can be used to assess the quality of blocking. \n",
    "\n",
    "Next step is to config a blocking job. Before we do that, let's look at the blocking methods we are currently supporting:\n",
    "\n",
    "1. Probabilistic signature (p-sig)\n",
    "2. LSH based $\\Lambda$-fold redundant (lambda-fold)\n",
    "\n",
    "Let's firstly look at P-sig\n",
    "\n",
    "### Blocking Methods - Probabilistic signature (p-sig)\n",
    "\n",
    "This blocking method uses signatures as the blocking key and place only records having same signatures into the same block. \n",
    "\n",
    "Let's see an example of configuration for `p-sig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocking_config = {\n",
    "    \"type\": \"p-sig\",\n",
    "    \"version\": 1,\n",
    "    \"config\": {\n",
    "        \"blocking_features\": [1],\n",
    "#         \"record-id-col\": 0,\n",
    "        \"filter\": {\n",
    "            \"type\": \"ratio\",\n",
    "            \"max\": 0.02,\n",
    "            \"min\": 0.00,\n",
    "        },\n",
    "        \"blocking-filter\": {\n",
    "            \"type\": \"bloom filter\",\n",
    "            \"number-hash-functions\": 4,\n",
    "            \"bf-len\": 2048,\n",
    "        },\n",
    "        \"signatureSpecs\": [\n",
    "            [\n",
    "                 {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 1},\n",
    "                 {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 2},\n",
    "            ],\n",
    "            [\n",
    "                {\"type\": \"metaphone\", \"feature-idx\": 1},\n",
    "                {\"type\": \"metaphone\", \"feature-idx\": 2},\n",
    "            ]\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1 - Generate Signature**\n",
    "\n",
    "For a record `r`, a signature is a sub-record deriving from record `r` with a signature strategy. For example, a signature strategy could be taking the initial of names and concatenating letters together i.e. if we have a record with name `\"John White\"` the signature for this record is `\"JW\"`.\n",
    "\n",
    "We provide the following signature strategies:\n",
    "\n",
    "* feature-value: the signature is generated by returning the selected feature\n",
    "* characters-at: the signature is generated by selecting a single character or a sequence of characters from selected feature\n",
    "* metaphone: the signature is generated by phonetic encoding the selected feature using metaphone\n",
    "\n",
    "The output of this step is a reversed index where keys are generated signatures / blocking key and the values are list of record IDs. The record IDs could be row index or the actual record identifier if it is available in the dataset.\n",
    "\n",
    "The configuration of signature strategies is in `signatureSpecs` section. For example, in the above configuration, we are going to generate two signatures for each record. The first signature is a combination of 3 signature strategies\n",
    "\n",
    "```\n",
    "     {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 1},\n",
    "     {\"type\": \"characters-at\", \"config\": {\"pos\": [0]}, \"feature-idx\": 2},\n",
    "     {\"type\": \"feature-value\", \"feature_idx\": 4}\n",
    "\n",
    "```\n",
    "It is a combination of name initials and postcode.\n",
    "\n",
    "The second signature is generated by a combination of 2 signatuer strategies:\n",
    "```\n",
    "    {\"type\": \"metaphone\", \"feature-idx\": 1},\n",
    "    {\"type\": \"metaphone\", \"feature-idx\": 2},\n",
    "```\n",
    "That is phonetic encoding of first name and last name.\n",
    "\n",
    "**Step2 - Filter Too Frequent Signatures**\n",
    "\n",
    "A signature is assumed to identify a record as uniquely as possible. Therefore, we need to filter out some too frequent signatures since they can uniquely identify the record. On the otherside, we want to be resilient to frequency attack, so we need to filter out too rare signature that only contains very few records. The configuration of filtering is in the `filter` part. For example, in the above configuration, the filter section is configured as:\n",
    "```\n",
    "    \"filter\": {\n",
    "        \"type\": \"ratio\",\n",
    "        \"max\": 0.02,\n",
    "        \"min\": 0.001,\n",
    "    }\n",
    "```\n",
    "Then we will filter out all signatures / blocks whose number of records is greater than 2% of number of total records or is less than 0.1% of number of total records. \n",
    "\n",
    "Note that we also support absoulte filtering configuration i.e. filter by number of counts. For example:\n",
    "\n",
    "```\n",
    "    \"filter\": {\n",
    "        \"type\": \"count\",\n",
    "        \"max\": 100,\n",
    "        \"min\": 5,\n",
    "    }\n",
    "```\n",
    "\n",
    "**Step3 - Anonymization**\n",
    "\n",
    "Given we want to do privacy preserving record linkage, the signatures need to be hashed to avoid leaking of PII information. The most frequent used data structure of such encoding is Bloom Filter. Here we use one Bloom Filter and map all filtered signatures into that Bloom Filter. The configuration of Bloom Filter is in `block-filter` section:\n",
    "\n",
    "```\n",
    "    \"blocking-filter\": {\n",
    "        \"type\": \"bloom filter\",\n",
    "        \"number-hash-functions\": 20,\n",
    "        \"bf-len\": 2048,\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "After anonymization, the signature becomes the set of indices of bits 1 in the bloom filter and hence can preseve the privacy of data for each data provider.\n",
    "\n",
    "### Carry out Blocking Job\n",
    "\n",
    "Okay, once you have a good understanding of the P-Sig blocking, we can carry out our blocking job with `blocklib`. Firstly, we need to process the data a bit since `blocklib` only accept list of tuples as input data.\n",
    "\n",
    "**Step1 - Generate Candidate Blocks for Party A - Alice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alice = df_alice.to_dict(orient='split')['data']\n",
    "print(\"Example PII\", data_alice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocklib import generate_candidate_blocks\n",
    "\n",
    "block_obj_alice = generate_candidate_blocks(data_alice, blocking_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics of blocks are printed for you to inspect the block distribution and decide if this is a good blocking result. Here both average and median block sizes are 1 which is resilient to frequency attack. \n",
    "\n",
    "You can get the blocking instance and blocks/reversed indice in the `block_obj_alice`. Let's get the first signature in the reversed indcies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(block_obj_alice.state)\n",
    "list(block_obj_alice.blocks.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the example signature for Alice is a set of indices of bits 1 in Bloom Filter. Next we want to do the same thing for another party - Bob.\n",
    "\n",
    "**Step2 - Generate Candidate Blocks for Party B - Bob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bob = pd.read_csv('data/bob.csv')\n",
    "data_bob = df_bob.to_dict(orient='split')['data']\n",
    "block_obj_bob = generate_candidate_blocks(data_bob, blocking_config)\n",
    "print(block_obj_bob.state)\n",
    "print(list(block_obj_bob.blocks.keys())[0])\n",
    "print(list(block_obj_bob.blocks.values())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Final Blocks\n",
    "\n",
    "Now we have candidate blocks from both parties, we can generate final blocks by only including signatures that appear in both parties. Instead of directly comparing signature, the algorithm will firstly map the list of signatures into a bloom filter for both parites, and then take the and operation on two bloom filter to decide the common ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocklib import generate_blocks_2party\n",
    "\n",
    "filtered_blocks_alice, filtered_blocks_bob = generate_blocks_2party([block_obj_alice, block_obj_bob])\n",
    "print('Alice: {} out of {} blocks are in common'.format(len(filtered_blocks_alice), len(block_obj_alice.blocks)))\n",
    "print('Bob:   {} out of {} blocks are in common'.format(len(filtered_blocks_bob), len(block_obj_bob.blocks)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Blocking\n",
    "\n",
    "We can assess the blocking result when we have ground truth . There are two main metrics to assess blocking result:\n",
    "\n",
    "* reduction ratio: the percentage of reduced number of comparisons\n",
    "* pair completeness: the percentage of true matches after blocking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blocklib.assess import assess_blocks_2party\n",
    "\n",
    "\n",
    "subdata1 = [[x[0]] for x in data_alice]\n",
    "subdata2 = [[x[0]] for x in data_bob]\n",
    "\n",
    "rr, pc = assess_blocks_2party([filtered_blocks_alice, filtered_blocks_bob],\n",
    "                              [subdata1, subdata2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking Methods - LSH Based $\\Lambda$-fold Redundant\n",
    "\n",
    "Now we look the other blocking method that we support - LSH Based $\\Lambda$-fold Redundant blocking.This blocking method uses the a list of selected bits selected randomly from Bloom Filter for each record as block keys. \n",
    "\n",
    "Let's see an example config of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocking_config = {\n",
    "    \"type\": \"lambda-fold\",\n",
    "    \"version\": 1,\n",
    "    \"config\": {\n",
    "        \"blocking-features\": [1, 2],\n",
    "        \"Lambda\": 5,\n",
    "        \"bf-len\": 2048,\n",
    "        \"num-hash-funcs\": 10,\n",
    "        \"K\": 40,\n",
    "        \"random_state\": 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now let's explain the meaning of each argument:\n",
    "\n",
    "* blocking-features: a list of feature indice that we are going to use to generate blocks\n",
    "* Lambda: this number denotes the degree of redundancy - $H^i$, $i=1,2,...,\\Lambda$ where each $H^i$ represents one independent blocking group\n",
    "* bf-len: length of Bloom Filter for each record\n",
    "* num-hash-funcs: number of hash functions used to map record to Bloom Filter\n",
    "* K: number of bits we selected from Bloom Filter for each record\n",
    "* random_state: control random seed\n",
    "\n",
    "Then we can carry out the blocking job and assess the result just like above steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating candidate blocks for Alice:')\n",
    "block_obj_alice = generate_candidate_blocks(data_alice, blocking_config)\n",
    "print()\n",
    "print('Generating candidate blocks for Bob: ')\n",
    "block_obj_bob = generate_candidate_blocks(data_bob, blocking_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_blocks_alice, filtered_blocks_bob = generate_blocks_2party([block_obj_alice, block_obj_bob])\n",
    "print('Alice: {} out of {} blocks are in common'.format(len(filtered_blocks_alice), len(block_obj_alice.blocks)))\n",
    "print('Bob:   {} out of {} blocks are in common'.format(len(filtered_blocks_bob), len(block_obj_bob.blocks)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr, pc = assess_blocks_2party([filtered_blocks_alice, filtered_blocks_bob],\n",
    "                              [subdata1, subdata2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
